{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "import gensim\n",
    "from gensim import utils\n",
    "import sys\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk import word_tokenize\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('./words/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "#model.save_word2vec_format('./words/GoogleNews-vectors-negative300.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "download('punkt') #tokenizer, run once\n",
    "download('stopwords') #stopwords dictionary, run once\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Excel on Mac saves csv file with delimiter ','\n",
    "# Because there are many comma in texts, you should change them into other characters like space ' '\n",
    "# I changed comma ',' in text to space' '\n",
    "photo_posts = pd.read_csv('cs_pytesseract.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_posts['manual'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_mask = photo_posts['manual'].isnull()\n",
    "\n",
    "idx = np.where(null_mask)\n",
    "idx\n",
    "#photo_posts[null_mask]['message']\n",
    "for i in idx:\n",
    "    photo_posts.loc[i, 'manual'] = ''\n",
    "\n",
    "\n",
    "\n",
    "#In [174]: mask = x[0]>0\n",
    "#In [175]: mask\n",
    "#Out[175]: array([False,  True, False,  True, False], dtype=bool)\n",
    "##In [176]: idx = np.where(mask)[0]\n",
    "#In [177]: idx\n",
    "#Out[177]: array([1, 3], dtype=int32)\n",
    "#In [178]: x[0, idx[1]]\n",
    "#Out[178]: 6.0\n",
    "\n",
    "photo_posts['manual'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_posts['ocr'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_mask = photo_posts['ocr'].isnull()\n",
    "\n",
    "idx = np.where(null_mask)\n",
    "idx\n",
    "#photo_posts[null_mask]['message']\n",
    "for i in idx:\n",
    "    photo_posts.loc[i, 'ocr'] = ''\n",
    "\n",
    "\n",
    "\n",
    "#In [174]: mask = x[0]>0\n",
    "#In [175]: mask\n",
    "#Out[175]: array([False,  True, False,  True, False], dtype=bool)\n",
    "##In [176]: idx = np.where(mask)[0]\n",
    "#In [177]: idx\n",
    "#Out[177]: array([1, 3], dtype=int32)\n",
    "#In [178]: x[0, idx[1]]\n",
    "#Out[178]: 6.0\n",
    "\n",
    "photo_posts['ocr'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manuals = photo_posts['manual'].tolist()\n",
    "ocrs = photo_posts['ocr'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_corpus = [preprocess(str(text)) for text in manuals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_corpus = [preprocess(str(ocr)) for ocr in ocrs]\n",
    "len(m_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_docs(corpus, texts, condition_on_doc):\n",
    "    \"\"\"\n",
    "    Filter corpus, texts and labels given the function condition_on_doc which takes\n",
    "    a doc.\n",
    "    The document doc is kept if condition_on_doc(doc) is true.\n",
    "    \"\"\"\n",
    "    number_of_docs = len(corpus)\n",
    "\n",
    "    #if texts is not None:\n",
    "    #    texts = [text for (text, doc) in zip(texts, corpus)\n",
    "    #             if condition_on_doc(doc)]\n",
    "\n",
    "    #labels = [i for (i, doc) in zip(labels, corpus) if condition_on_doc(doc)]\n",
    "    #corpus = [doc for doc in corpus if condition_on_doc(doc)]\n",
    "    \n",
    "    if texts is not None:\n",
    "        for i in range(number_of_docs):\n",
    "            doc = corpus[i]\n",
    "            if condition_on_doc(doc) is False or doc == 'nan':\n",
    "                texts[i] = ''\n",
    "                corpus[i] = []\n",
    "                \n",
    "\n",
    "    print(\"{} docs removed\".format(number_of_docs - len(corpus)))\n",
    "\n",
    "    return (corpus, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove OOV words and documents with no words in model dictionary\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    return np.mean(word2vec_model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 docs removed\n"
     ]
    }
   ],
   "source": [
    "t_corpus, manuals = filter_docs(t_corpus, manuals, lambda doc: has_vector_representation(model, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 docs removed\n"
     ]
    }
   ],
   "source": [
    "m_corpus, ocrs = filter_docs(m_corpus, ocrs, lambda doc: has_vector_representation(model, doc))\n",
    "#m_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 =[]\n",
    "for doc in t_corpus: #look up each doc in model\n",
    "    #print(\"i: \", i)\n",
    "    #i = i + 1\n",
    "    if len(doc) == 0:\n",
    "        x1.append(np.zeros((300,)))\n",
    "    else:\n",
    "        x1.append(document_vector(model, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2 =[]\n",
    "i = 0\n",
    "for doc in m_corpus: #look up each doc in model\n",
    "    #print(\"i: \", i)\n",
    "    #i = i + 1\n",
    "    if len(doc) == 0:\n",
    "        x2.append(np.zeros((300,)))\n",
    "    else:\n",
    "        x2.append(document_vector(model, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19355321]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(x1[0].reshape(1,300), x2[0].reshape(1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.193553\n",
      "0.0\n",
      "1.0\n",
      "0.328193\n",
      "0.149716\n",
      "0.970492\n",
      "0.761569\n",
      "0.423941\n",
      "0.984932\n",
      "0.986207\n",
      "0.298253\n",
      "0.793486\n",
      "0.624453\n",
      "0.096267\n",
      "0.173068\n",
      "0.0\n",
      "0.890463\n",
      "0.841714\n",
      "0.46813\n",
      "0.0\n",
      "0.754769\n",
      "0.0\n",
      "0.199203\n",
      "0.690282\n",
      "0.943864\n",
      "0.168511\n",
      "1.0\n",
      "0.825322\n",
      "0.524189\n",
      "0.656407\n",
      "0.0\n",
      "1.0\n",
      "0.978913\n",
      "0.78532\n",
      "0.987495\n",
      "0.0466278\n",
      "0.851722\n",
      "0.216375\n",
      "0.11087\n",
      "0.646818\n",
      "0.461531\n",
      "1.0\n",
      "0.948348\n",
      "0.712156\n",
      "0.721305\n",
      "0.918384\n",
      "0.332226\n",
      "1.0\n",
      "0.988905\n",
      "0.0\n",
      "0.0\n",
      "0.76161\n",
      "0.978913\n",
      "0.985233\n",
      "0.873303\n",
      "0.258489\n",
      "0.729841\n",
      "0.865311\n",
      "0.966607\n",
      "0.81711\n",
      "0.917696\n",
      "0.772217\n",
      "0.644702\n",
      "0.990154\n",
      "0.953024\n",
      "0.768904\n",
      "0.883063\n",
      "0.969385\n",
      "0.987001\n",
      "0.979944\n",
      "0.872394\n",
      "0.380259\n",
      "0.914013\n",
      "0.801914\n",
      "0.960069\n",
      "0.0\n",
      "0.99204\n",
      "0.512558\n",
      "0.0\n",
      "0.926146\n",
      "1.0\n",
      "0.883063\n",
      "0.935791\n",
      "1.0\n",
      "0.84058\n",
      "1.0\n",
      "0.758955\n",
      "0.991987\n",
      "0.699915\n",
      "0.978906\n",
      "0.860399\n",
      "0.860399\n",
      "0.881249\n",
      "0.647007\n",
      "0.984398\n",
      "0.98718\n",
      "0.802524\n",
      "0.749554\n",
      "0.978005\n",
      "0.412551\n",
      "0.600965\n",
      "0.979819\n",
      "0.813467\n",
      "0.862722\n",
      "0.915541\n",
      "0.349743\n",
      "0.931404\n",
      "0.598852\n",
      "0.363866\n",
      "0.813467\n",
      "0.813467\n",
      "0.988782\n",
      "0.979905\n",
      "0.932914\n",
      "0.431114\n",
      "0.992684\n",
      "0.73133\n",
      "0.969761\n",
      "0.977898\n",
      "0.967094\n",
      "0.763985\n",
      "0.577823\n",
      "0.551727\n",
      "0.0\n",
      "0.987282\n",
      "0.661198\n",
      "0.421544\n",
      "0.990113\n",
      "0.990469\n",
      "0.686366\n",
      "0.567797\n",
      "0.961312\n",
      "0.294694\n",
      "0.110429\n",
      "0.679459\n",
      "0.394838\n",
      "0.557797\n",
      "0.0\n",
      "0.979242\n",
      "0.842864\n",
      "0.56305\n",
      "0.0\n",
      "0.913945\n",
      "0.96951\n",
      "0.943652\n",
      "0.769002\n",
      "0.947457\n",
      "0.966643\n",
      "0.448519\n",
      "0.976442\n",
      "0.0\n",
      "0.837591\n",
      "0.975723\n",
      "0.0504244\n",
      "0.985924\n",
      "0.808713\n",
      "0.903225\n",
      "0.830433\n",
      "0.824123\n",
      "0.81569\n",
      "0.849277\n",
      "0.855889\n",
      "0.836586\n",
      "0.890256\n"
     ]
    }
   ],
   "source": [
    "sim_list =[]\n",
    "#i = 0\n",
    "for (x1i, x2i) in zip(x1, x2):\n",
    "    #print(x[i], y[i])\n",
    "    x1i = x1i.reshape(1,300)\n",
    "    x2i = x2i.reshape(1,300)\n",
    "    sim = cosine_similarity(x1i, x2i)\n",
    "    sim_list.append(sim[0,0])\n",
    "    print(sim[0,0])\n",
    "    #i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19355321,\n",
       " 0.0,\n",
       " 0.99999988,\n",
       " 0.32819265,\n",
       " 0.1497165,\n",
       " 0.97049177,\n",
       " 0.76156884,\n",
       " 0.42394114,\n",
       " 0.98493189,\n",
       " 0.98620713,\n",
       " 0.29825336,\n",
       " 0.79348552,\n",
       " 0.62445307,\n",
       " 0.096267015,\n",
       " 0.17306811,\n",
       " 0.0,\n",
       " 0.89046305,\n",
       " 0.84171391,\n",
       " 0.46813041,\n",
       " 0.0,\n",
       " 0.75476903,\n",
       " 0.0,\n",
       " 0.19920343,\n",
       " 0.69028187,\n",
       " 0.94386423,\n",
       " 0.16851148,\n",
       " 1.0,\n",
       " 0.82532239,\n",
       " 0.52418864,\n",
       " 0.65640652,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.97891331,\n",
       " 0.78532016,\n",
       " 0.98749459,\n",
       " 0.046627764,\n",
       " 0.85172212,\n",
       " 0.21637504,\n",
       " 0.11087016,\n",
       " 0.64681804,\n",
       " 0.46153104,\n",
       " 1.0000001,\n",
       " 0.9483484,\n",
       " 0.71215558,\n",
       " 0.72130477,\n",
       " 0.91838408,\n",
       " 0.33222643,\n",
       " 0.99999988,\n",
       " 0.98890543,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.76160991,\n",
       " 0.97891331,\n",
       " 0.98523301,\n",
       " 0.87330347,\n",
       " 0.25848871,\n",
       " 0.72984087,\n",
       " 0.86531097,\n",
       " 0.96660674,\n",
       " 0.81711042,\n",
       " 0.91769618,\n",
       " 0.77221745,\n",
       " 0.64470232,\n",
       " 0.99015403,\n",
       " 0.95302385,\n",
       " 0.76890379,\n",
       " 0.88306296,\n",
       " 0.96938533,\n",
       " 0.98700058,\n",
       " 0.97994429,\n",
       " 0.87239414,\n",
       " 0.38025871,\n",
       " 0.91401267,\n",
       " 0.80191427,\n",
       " 0.96006942,\n",
       " 0.0,\n",
       " 0.9920395,\n",
       " 0.51255774,\n",
       " 0.0,\n",
       " 0.92614615,\n",
       " 1.0000002,\n",
       " 0.88306296,\n",
       " 0.93579054,\n",
       " 0.99999994,\n",
       " 0.84057957,\n",
       " 0.99999964,\n",
       " 0.75895476,\n",
       " 0.99198735,\n",
       " 0.69991523,\n",
       " 0.97890556,\n",
       " 0.86039901,\n",
       " 0.86039901,\n",
       " 0.88124889,\n",
       " 0.64700693,\n",
       " 0.98439789,\n",
       " 0.98718023,\n",
       " 0.80252433,\n",
       " 0.74955374,\n",
       " 0.97800487,\n",
       " 0.41255128,\n",
       " 0.60096478,\n",
       " 0.9798193,\n",
       " 0.81346679,\n",
       " 0.86272204,\n",
       " 0.91554141,\n",
       " 0.34974343,\n",
       " 0.93140405,\n",
       " 0.59885234,\n",
       " 0.36386627,\n",
       " 0.81346679,\n",
       " 0.81346679,\n",
       " 0.98878169,\n",
       " 0.97990489,\n",
       " 0.93291438,\n",
       " 0.43111366,\n",
       " 0.99268419,\n",
       " 0.73133016,\n",
       " 0.96976054,\n",
       " 0.977898,\n",
       " 0.96709424,\n",
       " 0.7639848,\n",
       " 0.57782274,\n",
       " 0.55172741,\n",
       " 0.0,\n",
       " 0.98728186,\n",
       " 0.6611976,\n",
       " 0.42154402,\n",
       " 0.99011266,\n",
       " 0.99046886,\n",
       " 0.68636638,\n",
       " 0.56779659,\n",
       " 0.96131158,\n",
       " 0.29469442,\n",
       " 0.11042941,\n",
       " 0.67945862,\n",
       " 0.39483809,\n",
       " 0.55779719,\n",
       " 0.0,\n",
       " 0.97924155,\n",
       " 0.8428641,\n",
       " 0.56305027,\n",
       " 0.0,\n",
       " 0.91394508,\n",
       " 0.96950972,\n",
       " 0.94365191,\n",
       " 0.7690025,\n",
       " 0.94745719,\n",
       " 0.96664304,\n",
       " 0.44851884,\n",
       " 0.97644198,\n",
       " 0.0,\n",
       " 0.83759052,\n",
       " 0.97572255,\n",
       " 0.050424416,\n",
       " 0.98592412,\n",
       " 0.80871308,\n",
       " 0.90322506,\n",
       " 0.83043301,\n",
       " 0.82412332,\n",
       " 0.81568968,\n",
       " 0.84927672,\n",
       " 0.85588938,\n",
       " 0.83658552,\n",
       " 0.89025581]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_READ_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'describe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c1e9c4b9e10c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'describe'"
     ]
    }
   ],
   "source": [
    "sim_list.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sim = pd.DataFrame(sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.696123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.322110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.521281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.820617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.966756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  164.000000\n",
       "mean     0.696123\n",
       "std      0.322110\n",
       "min      0.000000\n",
       "25%      0.521281\n",
       "50%      0.820617\n",
       "75%      0.966756\n",
       "max      1.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sim.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv]",
   "language": "python",
   "name": "conda-env-opencv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
